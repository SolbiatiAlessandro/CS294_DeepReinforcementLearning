{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HW1 solution\n",
    "======"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Behavioural cloning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 22.06.2019 (alex)\n",
    "\n",
    "<p>So currently we are working on improving our behavioural cloning model and in the meanwhile learn how to build better neural nets. The bottleneck of the project is that we can't still run roboschool gym on the cloud, so for now trainers **can not use roboschool library**, this means that dataset must be generated locally and then uploaded on the cloud.</p>\n",
    "<br>\n",
    "<ul>To be done\n",
    "    <li>[ ] Run notebook and check that everything work</li>\n",
    "    <li>[ ] Implement validation set and put validation score as output2 of train_and_save</li>\n",
    "    <li>[ ] After having checked that scores make sense try to improve model, some ideas: add regularization like dropout layers</li></ul>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not found (2)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "DATA_FOLDER = (\"../../gcloud_data\")\n",
    "# https://storage.googleapis.com/relna-mlengine/data/RoboschoolHumanoid-v1-small.pkl\n",
    "try:\n",
    "    expert_rollouts = pk.load(open(os.path.join(DATA_FOLDER, \"RoboschoolHumanoid-v1-small.pkl\"),\"rb\"))\n",
    "except FileNotFoundError:\n",
    "    print(\"not found (1)\")\n",
    "    pass\n",
    "try:\n",
    "    expert_rollouts = pk.load(open(os.path.join(DATA_FOLDER, \"RoboschoolHumanoid-v1.pkl\"),\"rb\"))\n",
    "except FileNotFoundError:\n",
    "    print(\"not found (2)\")\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    assert(expert_rollouts)\n",
    "except:\n",
    "    print(\"###### (relna) MISSING DATA\\nThe data to run this model is not there, to get the data run the following command from /relna-client\\n\\\n",
    "    (venv) python relna.py --command data\\nto download the data of the trainer you forked\\n######\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18147, 44)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert_rollouts['observations'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18147, 17)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert_rollouts['actions'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert_rollouts['returns'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = expert_rollouts['observations']\n",
    "outputs = expert_rollouts['actions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(inputs) == len(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14517\n"
     ]
    }
   ],
   "source": [
    "split = int(len(inputs)*0.8)\n",
    "print(split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = inputs[:split], outputs[:split]\n",
    "X_test, y_test = inputs[split:], outputs[split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model\n",
    "========"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "# (alex) you may need to pip install this since they are not in the requirement of relna\n",
    "# if you want to do this professionally you can deactivate relna-client virtualenv and create a new one\n",
    "# with anaconda in case you are having problem, don't forget to reactivate relna-client when you want to ship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_reset():\n",
    "    try:\n",
    "        sess.close()\n",
    "    except:\n",
    "        pass\n",
    "    tf.reset_default_graph()\n",
    "    return tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf_reset()\n",
    "def create_model():\n",
    "    input_ph = tf.placeholder(dtype=tf.float32, shape=[None, 44]) # [None, 1] is because is 1D array\n",
    "    output_ph = tf.placeholder(dtype=tf.float32, shape=[None, 17])\n",
    "    \n",
    "    W0 = tf.get_variable(name='W0', shape=[44, 30], initializer = tf.contrib.layers.variance_scaling_initializer())\n",
    "    W1 = tf.get_variable(name='W1', shape=[30, 23], initializer = tf.contrib.layers.variance_scaling_initializer())\n",
    "    W2 = tf.get_variable(name='W2', shape=[23, 17], initializer = tf.contrib.layers.variance_scaling_initializer())\n",
    "    \n",
    "    \n",
    "    b0 = tf.get_variable(name='b0', shape=[30], initializer = tf.constant_initializer(0))\n",
    "    b1 = tf.get_variable(name='b1', shape=[23], initializer = tf.constant_initializer(0))\n",
    "    b2 = tf.get_variable(name='b2', shape=[17], initializer = tf.constant_initializer(0))\n",
    "    \n",
    "    weights = [W0, W1, W2]\n",
    "    biases = [b0, b1, b2]\n",
    "    activations = [tf.nn.relu, tf.nn.relu, None]\n",
    "    \n",
    "    layer = input_ph\n",
    "    for W, b, activation in zip(weights, biases, activations):\n",
    "        layer = tf.matmul(layer, W) + b\n",
    "        if activation is not None:\n",
    "            layer = activation(layer)\n",
    "            \n",
    "    output_pred = layer\n",
    "    return input_ph, output_ph, output_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0623 02:19:07.183829 4368221632 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_ph, output_ph, output_pred = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mse = tf.reduce_mean(0.5 * tf.square(output_pred - output_ph)) # this is the mean square error\n",
    "opt = tf.train.AdamOptimizer().minimize(mse) # this is an operation that pereform gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver() # save weight as the training goes on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0000 mse : 0.902\n",
      "1000 mse : 0.031\n",
      "2000 mse : 0.027\n",
      "3000 mse : 0.023\n",
      "4000 mse : 0.025\n",
      "5000 mse : 0.018\n",
      "6000 mse : 0.029\n",
      "7000 mse : 0.028\n",
      "8000 mse : 0.014\n",
      "9000 mse : 0.013\n",
      "10000 mse : 0.020\n",
      "11000 mse : 0.016\n",
      "12000 mse : 0.026\n",
      "13000 mse : 0.016\n",
      "14000 mse : 0.012\n"
     ]
    }
   ],
   "source": [
    "#training\n",
    "batch_size = 32\n",
    "training_mse = []\n",
    "for training_step in range(15000):\n",
    "    #random batch\n",
    "    indices = np.random.randint(low = 0, high = len(X_train), size = batch_size)\n",
    "    input_batch = X_train[indices]\n",
    "    output_batch = y_train[indices]\n",
    "    \n",
    "    # run optimizer and get mse\n",
    "    _, mse_run = sess.run([opt, mse], feed_dict={input_ph: input_batch, output_ph: output_batch})\n",
    "    \n",
    "    training_mse.append(mse_run)\n",
    "    if training_step % 1000 == 0:\n",
    "        print('{0:04d} mse : {1:.3f}'.format(training_step, mse_run))\n",
    "        saver.save(sess, '/tmp/model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(training_mse)\n",
    "plt.show()\n",
    "#run two times if it doesn't show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0623 02:19:18.362307 4368221632 deprecation.py:323] From /Users/lessandro/Coding/AI/relna-client/venv/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    }
   ],
   "source": [
    "sess = tf_reset()\n",
    "\n",
    "input_ph, output_ph, output_pred = create_model()\n",
    "saver = tf.train.Saver() \n",
    "saver.restore(sess, \"/tmp/model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction of only one action\n",
    "output_pred_run = sess.run(output_pred, feed_dict={input_ph: X_test[0].reshape((1,44))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.44887227,  0.5556406 , -0.039625  , -0.34997684,  1.1007566 ,\n",
       "         0.7015681 ,  1.2882776 , -0.31304693,  0.5416839 , -0.45720035,\n",
       "         0.17976025,  0.95606875,  0.34369785, -0.4842897 ,  0.05531599,\n",
       "        -0.00727031, -0.89326584]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_pred_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.67215571,  0.51215087,  0.16319634, -0.30910832,  1.15198657,\n",
       "        0.38291435,  1.11849179, -0.04375689,  0.68908028, -0.61239793,\n",
       "        0.25298019,  1.2005717 ,  0.26903097, -0.57398159,  0.43115737,\n",
       "        0.01838841, -0.88039469])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = ((output_pred_run[0] - y_test[0])**2).mean(axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.033336356248014634"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse # this is the current output_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMITATION LEARNING\n",
    "this part is to actually make run the robot and requires roboschool, so none of the following code can be run on the cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym, roboschool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "env=gym.make(\"RoboschoolHumanoid-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TimeLimit<RoboschoolHumanoid<RoboschoolHumanoid-v1>>>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['task.py',\n",
       " 'BehaviouralCloning-RoboschoolHumanoid.ipynb',\n",
       " 'Untitled.ipynb',\n",
       " '__init__.py',\n",
       " '__pycache__',\n",
       " 'tf_util.py',\n",
       " 'model.py',\n",
       " 'utils.py',\n",
       " '.ipynb_checkpoints',\n",
       " 'run_expert.py',\n",
       " 'GCSproxy.py']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os;os.listdir('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import run_expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Policy():\n",
    "    def __init__(self):\n",
    "        self.sess = tf_reset()\n",
    "\n",
    "        self.input_ph, self.output_ph, self.output_pred = create_model()\n",
    "        saver = tf.train.Saver() \n",
    "        saver.restore(self.sess, \"/tmp/model.ckpt\")\n",
    "        \n",
    "    def act(self, obs):\n",
    "        return self.sess.run(self.output_pred, feed_dict={self.input_ph: obs.reshape((1,44))})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy=Policy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0\n",
      "iter 1\n",
      "iter 2\n",
      "iter 3\n",
      "iter 4\n",
      "iter 5\n",
      "iter 6\n",
      "iter 7\n",
      "iter 8\n",
      "iter 9\n",
      "iter 10\n",
      "iter 11\n",
      "iter 12\n",
      "iter 13\n",
      "iter 14\n",
      "iter 15\n",
      "iter 16\n",
      "iter 17\n",
      "iter 18\n",
      "iter 19\n",
      "Env description: running trained model\n",
      "mean return 30.392201813197744\n",
      "std of return 28.286286334018502\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'observations': array([[ 6.0000002e-01, -1.6556273e-01,  9.8619926e-01, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 5.9781396e-01, -1.6427714e-01,  9.8641425e-01, ...,\n",
       "         -4.2621097e-01,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 5.8960938e-01, -1.6590416e-01,  9.8614186e-01, ...,\n",
       "         -1.1224823e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        ...,\n",
       "        [ 1.7507549e-02,  5.7226026e-01,  8.2007205e-01, ...,\n",
       "         -3.7525297e-04,  1.0000000e+00,  1.0000000e+00],\n",
       "        [ 1.8640765e-03,  5.9334326e-01,  8.0494958e-01, ...,\n",
       "         -2.0515840e-04,  1.0000000e+00,  1.0000000e+00],\n",
       "        [-1.5201756e-02,  6.1325723e-01,  7.8988326e-01, ...,\n",
       "         -2.1969201e-04,  1.0000000e+00,  1.0000000e+00]], dtype=float32),\n",
       " 'actions': array([[-5.0613642e-02,  1.2243503e-01,  4.8368841e-01, ...,\n",
       "         -3.1012356e-01,  1.4172712e-01, -2.2771969e-01],\n",
       "        [-2.2440225e-01,  3.5924914e-01, -1.2856810e-01, ...,\n",
       "         -6.1778492e-01, -1.0775320e-01, -3.9788529e-01],\n",
       "        [-5.7694143e-01,  4.9682781e-01, -4.0409619e-01, ...,\n",
       "         -7.6276392e-01,  3.1082332e-04, -4.7290406e-01],\n",
       "        ...,\n",
       "        [ 1.7651044e-01,  6.5028340e-02, -1.7264125e-01, ...,\n",
       "         -5.7190514e-01, -7.9356879e-02, -3.9840692e-01],\n",
       "        [ 1.5014744e-01,  6.3690335e-02, -2.0941374e-01, ...,\n",
       "         -5.3441823e-01, -4.8285902e-02, -3.9480025e-01],\n",
       "        [ 1.0709095e-01,  7.5845271e-02, -2.2896379e-01, ...,\n",
       "         -5.1029551e-01, -3.3602118e-05, -3.8851076e-01]], dtype=float32),\n",
       " 'returns': array([ 21.04724563,   7.52728156,  23.89844421, -19.45261596,\n",
       "          0.38244238,  66.41998044,  27.50125198,  25.8357947 ,\n",
       "         84.44974692,  50.43632451,  37.54963616,  59.5972371 ,\n",
       "        -17.68195544,  65.88737593,  58.17862416,  20.32033371,\n",
       "         12.30692659,   3.35858318,  59.07610491,  21.20527359])}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_expert.run_policy(env,policy,20,\"running trained model\",render=True,max_timesteps=100000)\n",
    "# here the mean return is the end goal of this task, the best I got is 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
