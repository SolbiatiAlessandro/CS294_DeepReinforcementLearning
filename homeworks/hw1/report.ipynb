{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HW1 solution\n",
    "======"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Behavioural cloning\n",
    "\n",
    "TODO:\n",
    "----\n",
    "1. generate rollouts\n",
    "This are sequences of the type expertSequence#1 = {s0 -> a0, s1 -> a1, s2 -> a3} done with the expert policy\n",
    "<br>\n",
    "\n",
    "- expert_data/something.pkl\n",
    "- big number -> 18101\n",
    "- observations.shape = (big number, 44)\n",
    "- actions.shape = (big number, 17)\n",
    "- returns.shape = (20, )\n",
    "<br>\n",
    "----\n",
    "2. implement behavioural cloning\n",
    "implement a neural net of the sort F(s) = a trained on all the expertSequence. Then create a policy using the neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_rollouts = pk.load(open(\"expert_data/RoboschoolHumanoid-v1.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'observations': array([[ 2.3841858e-08,  1.7628326e-01,  9.8433948e-01, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [-2.1484853e-03,  1.6638857e-01,  9.8606026e-01, ...,\n",
       "         -7.1955717e-01,  0.0000000e+00,  0.0000000e+00],\n",
       "        [-8.5775014e-03,  1.4194125e-01,  9.8987508e-01, ...,\n",
       "         -6.6612923e-01,  0.0000000e+00,  0.0000000e+00],\n",
       "        ...,\n",
       "        [-4.0738460e-01, -1.3294163e-01,  9.9112386e-01, ...,\n",
       "          3.7752178e-02,  1.0000000e+00,  0.0000000e+00],\n",
       "        [-4.0473124e-01, -2.1884102e-01,  9.7576052e-01, ...,\n",
       "          1.5287129e-02,  1.0000000e+00,  0.0000000e+00],\n",
       "        [-4.0661630e-01, -3.0624390e-01,  9.5195311e-01, ...,\n",
       "          6.2616086e-03,  1.0000000e+00,  0.0000000e+00]], dtype=float32),\n",
       " 'actions': array([[-0.82425266,  0.85833374,  0.25510112, ..., -0.63416464,\n",
       "         -0.02664589, -0.3858894 ],\n",
       "        [-0.55048927,  0.23574406,  0.66313531, ..., -0.77063167,\n",
       "         -0.04402356,  0.10912636],\n",
       "        [ 0.37136537,  0.39203157,  0.46709945, ..., -0.75028821,\n",
       "         -0.22311335, -0.2071629 ],\n",
       "        ...,\n",
       "        [ 0.00693983, -0.0300374 ,  0.15585705, ...,  0.5092681 ,\n",
       "         -0.64121948, -0.23524343],\n",
       "        [ 0.09773411, -0.31328689,  0.04197588, ...,  0.20837076,\n",
       "         -0.41147138, -0.34016665],\n",
       "        [ 0.47215537, -0.69121841, -0.06701108, ..., -0.99534443,\n",
       "          0.00836625, -0.49818358]]),\n",
       " 'returns': array([3243.94282602, 3268.7153319 , 3241.90955045, 3256.61222397,\n",
       "        3062.51128992, 3198.97302215, 3246.74606803, 3144.68853102,\n",
       "        3216.0104822 ,  -15.15474433, 3275.96192463, 3252.02060342,\n",
       "        3276.68093938, 3254.14696697, 3238.94268807, 3226.15165505,\n",
       "         -24.33710314, 3246.14015338, 3238.57608844, 3262.12627266])}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert_rollouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18091, 44)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert_rollouts['observations'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18091, 17)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert_rollouts['actions'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert_rollouts['returns'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = expert_rollouts['observations']\n",
    "outputs = expert_rollouts['actions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(inputs) == len(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14472\n"
     ]
    }
   ],
   "source": [
    "split = int(len(inputs)*0.8)\n",
    "print(split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = inputs[:split], outputs[:split]\n",
    "X_test, y_test = inputs[split:], outputs[split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model\n",
    "========"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_reset():\n",
    "    try:\n",
    "        sess.close()\n",
    "    except:\n",
    "        pass\n",
    "    tf.reset_default_graph()\n",
    "    return tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf_reset()\n",
    "def create_model():\n",
    "    input_ph = tf.placeholder(dtype=tf.float32, shape=[None, 44]) # [None, 1] is because is 1D array\n",
    "    output_ph = tf.placeholder(dtype=tf.float32, shape=[None, 17])\n",
    "    \n",
    "    W0 = tf.get_variable(name='W0', shape=[44, 30], initializer = tf.contrib.layers.variance_scaling_initializer())\n",
    "    W1 = tf.get_variable(name='W1', shape=[30, 23], initializer = tf.contrib.layers.variance_scaling_initializer())\n",
    "    W2 = tf.get_variable(name='W2', shape=[23, 17], initializer = tf.contrib.layers.variance_scaling_initializer())\n",
    "    \n",
    "    \n",
    "    b0 = tf.get_variable(name='b0', shape=[30], initializer = tf.constant_initializer(0))\n",
    "    b1 = tf.get_variable(name='b1', shape=[23], initializer = tf.constant_initializer(0))\n",
    "    b2 = tf.get_variable(name='b2', shape=[17], initializer = tf.constant_initializer(0))\n",
    "    \n",
    "    weights = [W0, W1, W2]\n",
    "    biases = [b0, b1, b2]\n",
    "    activations = [tf.nn.relu, tf.nn.relu, None]\n",
    "    \n",
    "    layer = input_ph\n",
    "    for W, b, activation in zip(weights, biases, activations):\n",
    "        layer = tf.matmul(layer, W) + b\n",
    "        if activation is not None:\n",
    "            layer = activation(layer)\n",
    "            \n",
    "    output_pred = layer\n",
    "    return input_ph, output_ph, output_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /Users/alex/Desktop/Coding/AI/CS294_DeepReinforcementLearning/homeworks/hw1/venv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "input_ph, output_ph, output_pred = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mse = tf.reduce_mean(0.5 * tf.square(output_pred - output_ph)) # this is the mean square error\n",
    "opt = tf.train.AdamOptimizer().minimize(mse) # this is an operation that pereform gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver() # save weight as the training goes on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0000 mse : 0.458\n",
      "1000 mse : 0.031\n",
      "2000 mse : 0.026\n",
      "3000 mse : 0.028\n",
      "4000 mse : 0.020\n"
     ]
    }
   ],
   "source": [
    "#training\n",
    "batch_size = 32\n",
    "training_mse = []\n",
    "for training_step in range(5000):\n",
    "    #random batch\n",
    "    indices = np.random.randint(low = 0, high = len(X_train), size = batch_size)\n",
    "    input_batch = X_train[indices]\n",
    "    output_batch = y_train[indices]\n",
    "    \n",
    "    # run optimizer and get mse\n",
    "    _, mse_run = sess.run([opt, mse], feed_dict={input_ph: input_batch, output_ph: output_batch})\n",
    "    \n",
    "    training_mse.append(mse_run)\n",
    "    if training_step % 1000 == 0:\n",
    "        print('{0:04d} mse : {1:.3f}'.format(training_step, mse_run))\n",
    "        saver.save(sess, '/tmp/model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(training_mse)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "sess = tf_reset()\n",
    "\n",
    "input_ph, output_ph, output_pred = create_model()\n",
    "saver = tf.train.Saver() \n",
    "saver.restore(sess, \"/tmp/model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation score was 0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction of only one action\n",
    "output_pred_run = sess.run(output_pred, feed_dict={input_ph: X_test[0].reshape((1,44))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.42027014,  0.30810767, -0.6921607 ,  0.66746587, -0.08639976,\n",
       "        -0.9280569 , -0.12618512,  0.49747017,  0.6034339 ,  1.0716732 ,\n",
       "         0.9731382 , -0.18995148, -0.22227001, -0.17566441, -0.5313878 ,\n",
       "        -0.36136973, -0.36491805]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_pred_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.44276008,  0.21976118, -0.57139829,  0.80728258, -0.17347842,\n",
       "       -0.86538909, -0.21637144,  0.33584227,  0.4801961 ,  1.11101721,\n",
       "        0.91422874, -0.32985784, -0.28811901, -0.10695498, -0.45460487,\n",
       "       -0.28110336, -0.49649675])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = ((output_pred_run[0] - y_test[0])**2).mean(axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.009805779074173392"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym, roboschool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alex/Desktop/Coding/AI/CS294_DeepReinforcementLearning/homeworks/hw1/venv/lib/python3.6/site-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n"
     ]
    }
   ],
   "source": [
    "env=gym.make(\"RoboschoolHumanoid-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TimeLimit<RoboschoolHumanoid<RoboschoolHumanoid-v1>>>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " '.ipynb_checkpoints',\n",
       " '.mypy_cache',\n",
       " '.run_expert.py.swp',\n",
       " '__pycache__',\n",
       " 'demo.bash',\n",
       " 'Dockerfile',\n",
       " 'expert_data',\n",
       " 'experts',\n",
       " 'imitation_trainer',\n",
       " 'load_policy.py',\n",
       " 'README.md',\n",
       " 'report.ipynb',\n",
       " 'report.md',\n",
       " 'requirements.txt',\n",
       " 'run_expert.py',\n",
       " 'template_trainer',\n",
       " 'tf_util.py',\n",
       " 'venv']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os;os.listdir('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import run_expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Policy():\n",
    "    def __init__(self):\n",
    "        self.sess = tf_reset()\n",
    "\n",
    "        self.input_ph, self.output_ph, self.output_pred = create_model()\n",
    "        saver = tf.train.Saver() \n",
    "        saver.restore(self.sess, \"/tmp/model.ckpt\")\n",
    "        \n",
    "    def act(self, obs):\n",
    "        return self.sess.run(self.output_pred, feed_dict={self.input_ph: obs.reshape((1,44))})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "policy=Policy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0\n",
      "iter 1\n",
      "iter 2\n",
      "iter 3\n",
      "iter 4\n",
      "iter 5\n",
      "iter 6\n",
      "iter 7\n",
      "iter 8\n",
      "iter 9\n",
      "iter 10\n",
      "iter 11\n",
      "iter 12\n",
      "iter 13\n",
      "iter 14\n",
      "iter 15\n",
      "iter 16\n",
      "iter 17\n",
      "iter 18\n",
      "iter 19\n",
      "Env description: running trained model\n",
      "mean return 19.445062228252716\n",
      "std of return 22.03125475034104\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'observations': array([[ 6.0000002e-01, -1.3641670e-01,  9.9065155e-01, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 5.9764951e-01, -1.0928621e-01,  9.9401033e-01, ...,\n",
       "         -6.5446183e-02,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 5.9032744e-01, -8.8491201e-02,  9.9607694e-01, ...,\n",
       "         -3.0168319e-01,  0.0000000e+00,  0.0000000e+00],\n",
       "        ...,\n",
       "        [ 3.0823695e-02,  3.8879395e-01,  9.2132473e-01, ...,\n",
       "          1.9786246e-04,  0.0000000e+00,  1.0000000e+00],\n",
       "        [ 1.2576728e-02,  4.3675664e-01,  8.9957970e-01, ...,\n",
       "         -1.2969035e-01,  0.0000000e+00,  1.0000000e+00],\n",
       "        [-6.9913077e-03,  4.9315590e-01,  8.6994094e-01, ...,\n",
       "          1.9295053e-01,  0.0000000e+00,  1.0000000e+00]], dtype=float32),\n",
       " 'actions': array([[ 0.37206176, -0.29462016,  0.5891975 , ..., -0.6602019 ,\n",
       "          0.29638252, -0.09097595],\n",
       "        [-1.1759261 , -0.19891082,  0.36412528, ..., -0.0667505 ,\n",
       "         -0.2717951 , -0.05463134],\n",
       "        [-0.4070432 ,  0.06346192,  0.4257569 , ..., -0.28002682,\n",
       "          0.28122032,  0.29190516],\n",
       "        ...,\n",
       "        [-0.31560788, -0.0559276 ,  0.03622217, ..., -0.15372917,\n",
       "         -0.32604906, -0.31058475],\n",
       "        [-0.22553343, -0.16532506, -0.20514366, ...,  0.05820961,\n",
       "         -0.06356667, -0.26745105],\n",
       "        [-0.4949533 , -0.300712  , -0.13941407, ...,  0.46892387,\n",
       "          0.08147201, -0.06061107]], dtype=float32),\n",
       " 'returns': array([ 22.25456868,  26.51985683,  20.44960279,  26.68214305,\n",
       "        -13.95620267,  26.58471385,  -9.28497704,  -7.80929967,\n",
       "         32.60369143,   7.19274656,  13.86156249,  14.47497923,\n",
       "         -9.2459387 ,  67.46157088,   9.19474651,  64.04455543,\n",
       "         48.24368331,  16.19912454,  30.93595553,   2.49416153])}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_expert.run_policy(env,policy,20,\"running trained model\",render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
