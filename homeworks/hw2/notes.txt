LunarLanderContinuous-v2
# Too see heuristic landing, run:
#
# python gym/envs/box2d/lunar_lander.py
#
# To play yourself, run:
#
# python examples/agents/keyboard_agent.py LunarLander-v0
#
InvertedPendulum-v2
CartPole-v0

(alex) why does tf.layers.dense has a kernel? isn't kernel only for convolutions layers?

help(tf.layers.dense):
dense(inputs, units, activation=None, use_bias=True, kernel_initializer=None, bias_initializer=<tensorflow.python.ops.init_ops.Zeros object at 0x129afa240>, kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, trainable=True, name=None, reuse=None)
    Functional interface for the densely-connected layer.

    This layer implements the operation:
    `outputs = activation(inputs.kernel + bias)`
    Where `activation` is the activation function passed as the `activation`
    argument (if not `None`), `kernel` is a weights matrix created by the layer,
    and `bias` is a bias vector created by the layer
    (only if `use_bias` is `True`).

    Arguments:
      inputs: Tensor input.
      units: Integer or Long, dimensionality of the output space.
      activation: Activation function (callable). Set it to None to maintain a
        linear activation.
      use_bias: Boolean, whether the layer uses a bias.
      kernel_initializer: Initializer function for the weight matrix.
        If `None` (default), weights are initialized using the default
        initializer used by `tf.get_variable`.
      bias_initializer: Initializer function for the bias.
      kernel_regularizer: Regularizer function for the weight matrix.
      bias_regularizer: Regularizer function for the bias.
      activity_regularizer: Regularizer function for the output.
      kernel_constraint: An optional projection function to be applied to the
          kernel after being updated by an `Optimizer` (e.g. used to implement
          norm constraints or value constraints for layer weights). The function
          must take as input the unprojected variable and must return the
          projected variable (which must have the same shape). Constraints are
          not safe to use when doing asynchronous distributed training.
      bias_constraint: An optional projection function to be applied to the
          bias after being updated by an `Optimizer`.
      trainable: Boolean, if `True` also add variables to the graph collection
        `GraphKeys.TRAINABLE_VARIABLES` (see `tf.Variable`).
      name: String, the name of the layer.
      reuse: Boolean, whether to reuse the weights of a previous layer
        by the same name.

    Returns:
      Output tensor the same shape as `inputs` except the last dimension is of


QUESTIONS (BLOG)
POLICY FORWARD PASS
what is policy_parameters?
this are the parmeter for the distribution.
Why policy is a distribution?
From the thoery part: More formally, π(θ) is a probability distribution over the action space, conditioned on the state.
DISCRETE CASE
sy_logits_na: these are the logits, that is the non-normalised output of the a multi-classification model (cat:50, dogs:100, duck:10). The logits are put into a softmax
the dimension of sy_logits_na is (batch_size, self.ac_dim). This means that for every obs in the batch, it gives you the probability of taking that action.
CONTINOUS CASE
sy_mean: this is the mean for every action in the continuous action space, and is the output of the regression model (policy). The dimensions is (batch_size, self.ac_dim) because for every observation in the batch, it gives you the mean of the value to take for every action in the action space. This is because in the continous case you take an action on every  continous axis (think of a car moving in x and y, at every steps you want to take an action on every continous axis. Whereas in the discrete case you just want to find out which is the optimal action to take from the set of available actions).

(Might be helpful to run the code with pdb attached to check what happens, otherwise looks to abstract.)

SAMPLE_ACTION
given a distritbution we need to sample an action.
we use numpy sampling functions. One case we need to sample from a multinomial distribution, from the other to a multivariate gaussian distribution.
